{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00ce03d4",
   "metadata": {},
   "source": [
    "# Install and load required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 4702,
     "status": "ok",
     "timestamp": 1745877899137,
     "user": {
      "displayName": "Jingyue Huang",
      "userId": "11611851786193480123"
     },
     "user_tz": 420
    },
    "id": "g4VJpcg4xiue"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import random\n",
    "from typing import List\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "from numpy.random import choice\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from symusic import Score\n",
    "from miditok import REMI, TokenizerConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AzLU_2qjxiug"
   },
   "source": [
    "# BaseLine \n",
    "##Markov Chain for MIDI generation\n",
    " Get the list of files for training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "executionInfo": {
     "elapsed": 43,
     "status": "ok",
     "timestamp": 1745878020365,
     "user": {
      "displayName": "Jingyue Huang",
      "userId": "11611851786193480123"
     },
     "user_tz": 420
    },
    "id": "58o78Ax9xiug"
   },
   "outputs": [],
   "source": [
    "train_files = glob.glob(\"./train/*.midi\")\n",
    "test_files = glob.glob(\"./test/*.midi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1745879773300,
     "user": {
      "displayName": "Jingyue Huang",
      "userId": "11611851786193480123"
     },
     "user_tz": 420
    },
    "id": "xxfY-aaBivYa",
    "outputId": "10776c74-a1eb-47a0-f140-124bd1f137a6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1745879926677,
     "user": {
      "displayName": "Jingyue Huang",
      "userId": "11611851786193480123"
     },
     "user_tz": 420
    },
    "id": "-555CKiQjXTC",
    "outputId": "d4607063-10e8-4f19-f1d3-79189808578a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./train\\\\MIDI-Unprocessed_01_R1_2006_01-09_ORIG_MID--AUDIO_01_R1_2006_01_Track01_wav.midi'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_files[0].encode('utf-8').decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1745879823823,
     "user": {
      "displayName": "Jingyue Huang",
      "userId": "11611851786193480123"
     },
     "user_tz": 420
    },
    "id": "o62L679Ii8ps",
    "outputId": "39a46746-708f-43be-8809-f0684364dc6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'./train\\\\MIDI-Unprocessed_01_R1_2006_01-09_ORIG_MID--AUDIO_01_R1_2006_01_Track01_wav.midi'\n"
     ]
    }
   ],
   "source": [
    "print(train_files[0].encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1745879781553,
     "user": {
      "displayName": "Jingyue Huang",
      "userId": "11611851786193480123"
     },
     "user_tz": 420
    },
    "id": "jY-AXtYNizw9",
    "outputId": "47c11385-d46c-4330-bacb-5dcf185ddec6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'./train\\\\MIDI-Unprocessed_01_R1_2006_01-09_ORIG_MID--AUDIO_01_R1_2006_01_Track01_wav.midi'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str.encode(train_files[0], 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zcnRQllAxiug"
   },
   "source": [
    "## Train your MIDI tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4871,
     "status": "ok",
     "timestamp": 1745878027318,
     "user": {
      "displayName": "Jingyue Huang",
      "userId": "11611851786193480123"
     },
     "user_tz": 420
    },
    "id": "i-fRQcSyxiug",
    "outputId": "f1abe86e-4a53-4ed9-ffe6-2e158ec4a409"
   },
   "outputs": [],
   "source": [
    "config = TokenizerConfig(num_velocities=1, use_chords=False, use_programs=True)\n",
    "tokenizer = REMI(config)\n",
    "tokenizer.train(vocab_size=1000, files_paths=train_files)\n",
    "tokenizer.save(\"tokenizer.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BxuSZPQGxiug"
   },
   "source": [
    "## Construct a PyTorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1745878029126,
     "user": {
      "displayName": "Jingyue Huang",
      "userId": "11611851786193480123"
     },
     "user_tz": 420
    },
    "id": "3XTgwwDbxiug"
   },
   "outputs": [],
   "source": [
    "class MIDIDataset(Dataset):\n",
    "    def __init__(self, file_paths: List[str], tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.file_paths = file_paths\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        midi = Score(self.file_paths[idx])\n",
    "        tokens = self.tokenizer(midi)\n",
    "        return np.array(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NDC-VgQ8xiug"
   },
   "source": [
    "## Define PyTorch datasets and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1745878030484,
     "user": {
      "displayName": "Jingyue Huang",
      "userId": "11611851786193480123"
     },
     "user_tz": 420
    },
    "id": "ZpF66QOKxiug"
   },
   "outputs": [],
   "source": [
    "train_dataset = MIDIDataset(train_files, tokenizer)\n",
    "test_dataset = MIDIDataset(test_files, tokenizer)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N1lYNgFYxiug"
   },
   "source": [
    "## Define a Second Order Markov Chain model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1745878032483,
     "user": {
      "displayName": "Jingyue Huang",
      "userId": "11611851786193480123"
     },
     "user_tz": 420
    },
    "id": "wbbkhpLZxiug"
   },
   "outputs": [],
   "source": [
    "class SecondOrderMarkovChain:\n",
    "    def __init__(self):\n",
    "        self.transitions = defaultdict(lambda: defaultdict(int))\n",
    "        self.probabilities = defaultdict(lambda: defaultdict(float))\n",
    "\n",
    "    def train(self, train_loader):\n",
    "        for sequence in train_loader:\n",
    "            sequence = sequence[0].numpy().astype(int)\n",
    "            for i in range(len(sequence) - 2):\n",
    "                state1, state2 = sequence[i], sequence[i + 1]\n",
    "                next_state = sequence[i + 2]\n",
    "                self.transitions[(state1, state2)][next_state] += 1\n",
    "\n",
    "        for (state1, state2), next_states in self.transitions.items():\n",
    "            total = sum(next_states.values())\n",
    "            for next_state, count in next_states.items():\n",
    "                self.probabilities[(state1, state2)][next_state] = count / total\n",
    "        return self.probabilities\n",
    "\n",
    "    def generate(self, test_sequence, num_predictions=1):\n",
    "        test_sequence = test_sequence[0].numpy().astype(int)\n",
    "        results = [test_sequence[0], test_sequence[1]]\n",
    "        for i in range(100):\n",
    "            if (results[-2], results[-1]) not in self.probabilities:\n",
    "                break\n",
    "            else:\n",
    "                probs = self.probabilities[(results[-2], results[-1])]\n",
    "                states = list(probs.keys())\n",
    "                probabilities = list(probs.values())\n",
    "                if not states:\n",
    "                    break\n",
    "                try:\n",
    "                    predictions = np.random.choice(states, size=num_predictions, p=probabilities)\n",
    "                except:\n",
    "                    break\n",
    "                results.append(predictions[0])\n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QzKyEWGNxiug"
   },
   "source": [
    "## Train your model and make inferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "executionInfo": {
     "elapsed": 3142,
     "status": "ok",
     "timestamp": 1745878037208,
     "user": {
      "displayName": "Jingyue Huang",
      "userId": "11611851786193480123"
     },
     "user_tz": 420
    },
    "id": "lbLz6RjZxiug"
   },
   "outputs": [],
   "source": [
    "def evaluate_markov_accuracy(model, test_loader, device='cpu'):\n",
    "    total_correct = 0\n",
    "    total_tokens = 0\n",
    "\n",
    "    for seq in test_loader:\n",
    "        if not isinstance(seq, torch.Tensor):\n",
    "            seq = torch.tensor(seq, dtype=torch.long)\n",
    "        seq = seq.to(device)\n",
    "\n",
    "        if seq.size(0) < 3:\n",
    "            continue\n",
    "\n",
    "        seed = seq[:2]\n",
    "        targets = seq[2:]\n",
    "        generated = model.generate(seed.tolist(), length=targets.size(0))\n",
    "        if not isinstance(generated, torch.Tensor):\n",
    "            generated = torch.tensor(generated, dtype=torch.long, device=device)\n",
    "\n",
    "        min_len = min(generated.size(0), targets.size(0))\n",
    "        total_correct += (generated[:min_len] == targets[:min_len]).sum().item()\n",
    "        total_tokens += min_len\n",
    "\n",
    "    if total_tokens == 0:\n",
    "        return 0.0\n",
    "\n",
    "    accuracy = total_correct / total_tokens\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}  ({total_correct}/{total_tokens})\")\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "model = SecondOrderMarkovChain()\n",
    "model.train(train_loader)\n",
    "acc = evaluate_markov_accuracy(model, test_loader, device=\"cpu\")\n",
    "\n",
    "predictions = []\n",
    "for test_sequence in test_loader:\n",
    "    predictions.append(model.generate(test_sequence))\n",
    "for i, prediction in enumerate(predictions):\n",
    "    output_score = tokenizer.decode(torch.Tensor(prediction))\n",
    "    output_score.dump_midi(f\"{i}.mid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V2w9rx8CX7SY"
   },
   "source": [
    "## A New Dataset for batch inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "PtVV2bvtkNZQ"
   },
   "outputs": [],
   "source": [
    "from miditok.pytorch_data import DatasetMIDI, DataCollator\n",
    "\n",
    "tokenizer = REMI()  # using defaults parameters (constants.py)\n",
    "train_dataset = DatasetMIDI(\n",
    "    files_paths=train_files,\n",
    "    tokenizer=tokenizer,\n",
    "    max_seq_len=1024,\n",
    "    bos_token_id=tokenizer[\"BOS_None\"],\n",
    "    eos_token_id=tokenizer[\"EOS_None\"],\n",
    ")\n",
    "test_dataset = DatasetMIDI(\n",
    "    files_paths=test_files,\n",
    "    tokenizer=tokenizer,\n",
    "    max_seq_len=1024,\n",
    "    bos_token_id=tokenizer[\"BOS_None\"],\n",
    "    eos_token_id=tokenizer[\"EOS_None\"],\n",
    ")\n",
    "collator = DataCollator(tokenizer.pad_token_id)\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collator)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False, collate_fn=collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1745713128943,
     "user": {
      "displayName": "Jingyue Huang",
      "userId": "11611851786193480123"
     },
     "user_tz": -120
    },
    "id": "eN62DQ2MbnvF",
    "outputId": "23e7fece-e34c-4065-ac0a-2c266e28ea59"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(235, 27)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader), len(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VR7hZbrLTyu1"
   },
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "wfddI849TzsN"
   },
   "outputs": [],
   "source": [
    "class MusicRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers):\n",
    "        super(MusicRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        # x: (batch_size, seq_length)\n",
    "        x = self.embedding(x)  # (batch_size, seq_length, embedding_dim)\n",
    "        out, hidden = self.rnn(x, hidden)  # out: (batch_size, seq_length, hidden_dim)\n",
    "        out = self.fc(out)  # (batch_size, seq_length, vocab_size)\n",
    "        return out, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aVSszSART00u"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 169117,
     "status": "ok",
     "timestamp": 1745714014906,
     "user": {
      "displayName": "Jingyue Huang",
      "userId": "11611851786193480123"
     },
     "user_tz": -120
    },
    "id": "-OelLTyQT3gY",
    "outputId": "f3ac99f9-eda4-4f20-c319-7746797ab340"
   },
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, vocab_size, num_epochs=5, lr=0.001, device='cpu'):\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    learning_rates = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "\n",
    "        for batch in train_loader:\n",
    "            batch = batch['input_ids'].to(device)\n",
    "            inputs = batch[:, :-1]\n",
    "            targets = batch[:, 1:]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs, _ = model(inputs)\n",
    "            outputs = outputs.reshape(-1, vocab_size)\n",
    "            targets = targets.reshape(-1)\n",
    "\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "\n",
    "        # --------- Validation ---------\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                batch = batch['input_ids'].to(device)\n",
    "                inputs = batch[:, :-1]\n",
    "                targets = batch[:, 1:]\n",
    "\n",
    "                outputs, _ = model(inputs)\n",
    "                outputs = outputs.reshape(-1, vocab_size)\n",
    "                targets = targets.reshape(-1)\n",
    "\n",
    "                loss = criterion(outputs, targets)\n",
    "                total_val_loss += loss.item()\n",
    "\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "\n",
    "        train_losses.append(avg_train_loss)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        learning_rates.append(optimizer.param_groups[0]['lr'])\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    return train_losses, val_losses, learning_rates\n",
    "\n",
    "\n",
    "def plot_training_progress(train_losses, val_losses, learning_rates):\n",
    "    #Plot training metrics to visualize progress\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Loss plot\n",
    "    axes[0].plot(train_losses, label='Training Loss', color='blue')\n",
    "    axes[0].plot(val_losses, label='Validation Loss', color='red')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].set_title('Training Progress')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True)\n",
    "    \n",
    "    # Learning rate plot\n",
    "    axes[1].plot(learning_rates, color='green')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Learning Rate')\n",
    "    axes[1].set_title('Learning Rate Schedule')\n",
    "    axes[1].set_yscale('log')\n",
    "    axes[1].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    vocab_size = tokenizer.vocab_size\n",
    "    embedding_dim = 256\n",
    "    hidden_dim = 512\n",
    "    num_layers = 2\n",
    "\n",
    "    model = MusicRNN(vocab_size, embedding_dim, hidden_dim, num_layers)\n",
    "    train_losses, val_losses, learning_rates = train(model, train_loader, test_loader, vocab_size)\n",
    "\n",
    "    try:\n",
    "        import matplotlib.pyplot as plt\n",
    "        plot_training_progress(train_losses, val_losses, learning_rates)\n",
    "    except ImportError:\n",
    "        print(\"Install matplotlib to see training plots: pip install matplotlib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(model, data_loader, vocab_size, device='cpu'):\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    total_correct = 0\n",
    "    total_tokens = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            batch = batch['input_ids'].to(device)\n",
    "            inputs = batch[:, :-1]\n",
    "            targets = batch[:, 1:]\n",
    "\n",
    "            outputs, _ = model(inputs)\n",
    "            outputs = outputs.reshape(-1, vocab_size)\n",
    "            targets = targets.reshape(-1)\n",
    "\n",
    "            preds = torch.argmax(outputs, dim=-1)\n",
    "            mask = targets != 0  # Ignore padding\n",
    "\n",
    "            correct = (preds == targets) & mask\n",
    "            total_correct += correct.sum().item()\n",
    "            total_tokens += mask.sum().item()\n",
    "   \n",
    "    accuracy = total_correct / total_tokens if total_tokens > 0 else 0\n",
    "    print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "train_acc = evaluate_accuracy(model, train_loader, vocab_size, device = \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v0NQxTiiT3-t"
   },
   "source": [
    "### Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 905,
     "status": "ok",
     "timestamp": 1745714020696,
     "user": {
      "displayName": "Jingyue Huang",
      "userId": "11611851786193480123"
     },
     "user_tz": -120
    },
    "id": "aqGTcuhtT7c6",
    "outputId": "89733c4f-9c1d-439a-f6cf-d96f8ed4d95b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated token sequence:\n",
      "[1, 4, 189, 43, 113, 127, 43, 113, 127, 48, 113, 127, 193, 48, 112, 125, 53, 112, 125, 195, 53, 112, 125, 197, 48, 112, 125, 198, 51, 111, 125, 200, 53, 112, 125, 198, 55, 112, 125, 199, 53, 112, 127, 200, 52, 112, 125, 48, 112, 125, 201, 50, 112, 125, 202, 53, 112, 125, 203, 53, 111, 126, 205, 48, 110, 125, 207, 55, 110, 125, 208, 43, 112, 125, 209, 51, 110, 125, 211, 46, 111, 125, 213, 53, 111, 125, 214, 55, 111, 125, 216, 58, 112, 125, 217, 55, 112, 125, 218, 53, 110, 125, 204, 53, 112, 125, 205, 51, 111, 140, 214, 51, 112, 147, 215, 55, 110, 138, 4, 189, 55, 115, 140, 197, 53, 113, 132, 205, 58, 114, 132, 48, 114, 132, 213, 55, 113, 132, 53, 113, 132, 48, 113, 132, 4, 189, 60, 115, 140, 65, 115, 140, 60, 115, 140, 41, 115, 140, 4, 189, 60, 116, 134, 44, 113, 140, 48, 113, 140, 197, 58, 112, 132, 205, 63, 115, 140, 43, 113, 132, 209, 48, 114, 132, 213, 55, 113, 132, 58, 113, 132, 38, 113, 130, 4, 189, 39, 114, 138, 193, 55, 112, 128, 197, 56, 111, 128, 43, 114, 132, 213, 51, 113, 128, 41, 113, 128, 4, 189, 53, 115, 128, 36, 116, 128, 193, 55, 115, 128, 43, 114, 128, 197, 53, 113, 128, 39, 114, 126, 199, 41, 113, 126, 201, 51, 114, 128, 36, 113, 128, 205, 31, 112, 132, 36, 112, 132, 205, 36, 113, 132, 209, 41, 112, 132, 44, 112, 132, 36, 113, 128, 213, 36, 111, 128, 217, 38, 111, 128, 38, 111, 136, 4, 189, 53, 113, 128, 29, 113, 140, 193, 53, 112, 128, 25, 112, 128, 197, 50, 112, 128, 39, 114, 128, 201, 43, 112, 136, 27, 112, 128, 205, 25, 113, 132, 209, 36, 113, 128, 213, 36, 111, 132, 217, 43, 111, 128, 4, 189, 31, 113, 128, 193, 36, 111, 128, 197, 48, 111, 132, 38, 112, 128, 201, 35, 112, 128, 205, 50, 114, 132, 31, 111, 132, 213, 36, 111, 128, 217, 43, 111, 128, 4, 189, 55, 114, 132, 41, 112, 136, 197, 53, 111, 128, 201, 62, 112, 128, 205, 53, 111, 128, 209, 53, 110, 128, 213, 53, 109, 132, 4, 189, 55, 111, 132, 48, 110, 132, 197, 46, 111, 132, 53, 111, 132, 205, 48, 112, 132, 53, 112, 132, 213, 55, 112, 132, 22, 111, 132, 4, 189, 48, 111, 140, 53, 110, 140, 193, 48, 111, 128, 197, 36, 110, 132, 205, 34, 110, 132, 205, 53, 113, 132, 34, 113, 132, 213, 36, 111, 132, 48, 111, 132, 4, 189, 46, 113, 132, 29, 113, 136, 197, 48, 111, 132, 22, 111, 132, 201, 48, 111, 128, 205, 53, 111, 132, 36, 111, 132, 213, 50, 111, 132, 55, 111, 132, 4, 189, 48, 112, 132, 53, 112, 132, 197, 43, 111, 132, 46, 111, 132, 205, 53, 114, 148, 29, 113, 132, 213, 34, 113, 132, 4, 132, 50, 113, 132, 4, 189, 51, 114, 132, 55, 114, 132, 60, 114, 132, 132, 41, 112, 132, 197, 51, 111, 132, 53, 111, 132, 58, 111, 132, 205, 53, 113, 132, 60, 113, 132, 58, 113, 132, 41, 111, 132, 213, 46, 110, 132, 51, 109, 132, 39, 111, 132, 4, 189, 60, 111, 132, 41, 112, 132, 46, 112, 132, 140, 60, 112, 130, 197, 58, 112, 132, 53, 112, 132, 58, 112, 132, 36, 111, 132, 205, 60, 113, 132, 63, 113, 132, 29, 111, 132, 213, 58, 111, 132, 34, 111, 132, 41, 111, 132, 4, 189, 60, 113, 132, 34, 111, 132, 34, 111, 132, 197, 67, 112, 128, 31, 110, 132, 44, 111, 132, 201, 43, 111, 128, 205, 60, 111, 128, 33, 111, 132, 209, 60, 111, 128, 213, 58, 111, 128, 36, 110, 132, 43, 110, 132, 217, 60, 110, 128, 4, 189, 56, 112, 132, 38, 112, 132, 43, 112, 132, 197, 60, 111, 128, 36, 111, 132, 43, 111, 132, 201, 63, 110, 128, 205, 60, 111, 132, 36, 111, 132, 48, 111, 132, 213, 60, 111, 132, 39, 110, 132, 43, 110, 132, 4, 189, 56, 112, 128, 39, 112, 132, 48, 112, 132, 193, 58, 110, 128, 197, 51, 110, 154, 43, 110, 132, 46, 110, 132, 205, 48, 110, 132, 34, 110, 132, 213, 51, 110, 128, 44, 110, 132, 217, 48, 110, 128, 4, 189, 51, 111, 132, 34, 113, 132, 41, 113, 132, 197, 53, 111, 132, 36, 110, 132, 43, 110, 132, 205, 51, 112, 128, 29, 111, 132, 40, 111, 132, 209, 60, 108, 128, 213, 60, 109, 128, 36, 109, 132, 43, 109, 132, 217, 58, 111, 128, 4, 189, 58, 111, 128, 41, 112, 132, 46, 112, 132, 193, 63, 110, 128, 197, 58, 110, 128, 36, 111, 132, 44, 111, 132, 43, 111, 132, 201, 60, 110, 128, 205, 60, 112, 132, 36, 111, 132, 42, 111, 132, 48, 111, 132, 213, 65, 112, 128, 41, 111, 132, 44, 111, 132, 217, 61, 111, 128, 4, 189, 61, 110, 132, 34, 110, 132, 43, 110, 132, 197, 58, 110, 128, 32, 110, 132, 43, 110, 132, 201, 58, 110, 128, 205, 63, 111, 156, 32, 111, 132, 39, 111, 132, 31, 111, 132, 205, 36, 110, 132, 209, 63, 111, 128, 213, 58, 109, 132, 38, 109, 132, 37, 111, 132, 41, 111, 132, 4, 189, 63, 109, 128, 44, 111, 132, 46, 111, 132, 193, 65, 110, 128, 197, 75, 110, 128, 41, 110, 132, 44, 110, 132, 201, 58, 109, 128, 205, 60, 109, 132, 44, 110, 132, 48, 110, 132, 44, 110, 132, 213, 63, 110, 128, 53, 110, 148, 43, 110, 132, 193, 64, 109, 128, 65, 111, 128, 205, 60, 110, 156, 41, 110, 140, 38, 110, 132, 43, 110, 132, 213, 34, 110, 132, 36, 110, 132, 4, 189, 63, 115, 136, 25, 114, 132, 29, 114, 132, 197, 62, 113, 128, 41, 112, 132, 198, 60, 113, 132, 37, 113, 136, 201, 60, 112]\n"
     ]
    }
   ],
   "source": [
    "def sample(model, start_token, max_length=100, temperature=1.0, device='cuda'):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    generated = [start_token]\n",
    "    input_token = torch.tensor([[start_token]], device=device)  # (1, 1)\n",
    "\n",
    "    hidden = None\n",
    "\n",
    "    for _ in range(max_length):\n",
    "        output, hidden = model(input_token, hidden)  # output: (1, 1, vocab_size)\n",
    "        output = output[:, -1, :]  # take the last output\n",
    "        output = output / temperature  # adjust randomness\n",
    "\n",
    "        probs = F.softmax(output, dim=-1)  # (1, vocab_size)\n",
    "        next_token = torch.multinomial(probs, num_samples=1).item()\n",
    "        generated.append(next_token)\n",
    "        if next_token == 2 or next_token == 0: # reach end of sequence\n",
    "          break\n",
    "\n",
    "        input_token = torch.tensor([[next_token]], device=device)\n",
    "\n",
    "    return generated\n",
    "\n",
    "start_token = tokenizer.special_tokens_ids[1]\n",
    "generated_sequence = sample(model, start_token, max_length=1024)\n",
    "\n",
    "print(\"Generated token sequence:\")\n",
    "print(generated_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pm3UPSBQqjU2"
   },
   "outputs": [],
   "source": [
    "from midi2audio import FluidSynth # Import library\n",
    "from IPython.display import Audio, display\n",
    "#fs = FluidSynth(\"FluidR3Mono_GM.sf3\") # Initialize FluidSynth\n",
    "\n",
    "output_score = tokenizer.tokens_to_midi([generated_sequence])\n",
    "output_score.dump_midi(f\"rnn.mid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OcYgd70BiyDY"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
